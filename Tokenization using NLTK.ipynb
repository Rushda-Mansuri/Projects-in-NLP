{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiL2nmB1WAQd"
      },
      "source": [
        "# <font color='#fd79a8'> Tokenization Methods Using NLTK<font/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKFaFq4vrvH4"
      },
      "outputs": [],
      "source": [
        "import nltk #importing nltk package "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "698RpQucr79J",
        "outputId": "4037ff57-80fa-4971-bde9-0c2e1a6bbdf8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgVZGbhouyyK"
      },
      "source": [
        "<font color= #fd79a8 > NLTK Module **tokenize()** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NImBGS2cvHgO"
      },
      "source": [
        "<font color= #fd79a8 > NLTK Module **word_tokenize()** method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2_BTyTCsbHN"
      },
      "outputs": [],
      "source": [
        "sentence = \"He's a German Shepherd. They are some of the smartest dogs!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js5ny_-UsgJ3",
        "outputId": "3e1f0b6e-4ddf-4c22-a0ea-741f9d5fb958"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['He',\n",
              " \"'s\",\n",
              " 'a',\n",
              " 'German',\n",
              " 'Shepherd',\n",
              " '.',\n",
              " 'They',\n",
              " 'are',\n",
              " 'some',\n",
              " 'of',\n",
              " 'the',\n",
              " 'smartest',\n",
              " 'dogs',\n",
              " '!']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokenize(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQlt1TFkEvjp"
      },
      "source": [
        "<font color= #fd79a8 > **sent_tokenization()** <font/> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwlgelVzwvBg"
      },
      "outputs": [],
      "source": [
        "article = '''Did you know that World War 1 brought German Shepherds to the Western Hemisphere? Rin Tin Tin was a German Shepherd rescued from WWI. They are some of the smartest dogs!'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEJq6wS4s1L7"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLPPgGrvtCHU",
        "outputId": "99ea2e6d-4252-4b89-db88-5b4477bf6b2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Did you know that World War 1 brought German Shepherds to the Western Hemisphere?',\n",
              " 'Rin Tin Tin was a German Shepherd rescued from WWI.',\n",
              " 'They are some of the smartest dogs!']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent_tokenize(article)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggnqvazO8Eqi"
      },
      "source": [
        "### <font color= #fd79a8 > **Expanding Clitics/Contractions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqU93z-l8fqm"
      },
      "source": [
        "##### Using Contractions library to expand clitics\n",
        "\n",
        "[Library source for contractions](https://github.com/kootenpv/contractions) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNjJbFug7udG",
        "outputId": "9cddc0f4-a325-4517-b503-b91fc3933a60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (110 kB)\n",
            "\u001b[K     |████████████████████████████████| 110 kB 42.9 MB/s \n",
            "\u001b[?25hCollecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 66.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.73 pyahocorasick-1.4.4 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwleBnwt-4gd"
      },
      "outputs": [],
      "source": [
        "import contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNodi-wh-66c"
      },
      "outputs": [],
      "source": [
        "contracted_text = ''' She's going for a walk.\n",
        "                      Jack didn't go. They'd definitely go tonight. I'm sorry, I'll be late.\n",
        "                      That's the way I like 'em!!! '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1A9RSrPa_Hm7"
      },
      "outputs": [],
      "source": [
        "expanded_all = []\n",
        "for word in contracted_text.split( ):\n",
        "    expanded_all.append(contractions.fix(word))\n",
        "#after splitting and expanding all clitics we join them back together\n",
        "\n",
        "expanded_clitics = ' '.join(expanded_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "losnBtWE_lof",
        "outputId": "d9235185-f57c-4777-80ff-30b3b30dfcf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text with contractions :  She's going for a walk.\n",
            "                      Jack didn't go. They'd definitely go tonight. I'm sorry, I'll be late.\n",
            "                      That's the way I like 'em!!! \n",
            "Expanded Clitics : She is going for a walk. Jack did not go. They would definitely go tonight. I am sorry, I will be late. That is the way I like them!!!\n"
          ]
        }
      ],
      "source": [
        "print(\"Text with contractions : \"+contracted_text)\n",
        "print(\"Expanded Clitics : \"+expanded_clitics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUnbinly_5pv"
      },
      "source": [
        "#### Tokenizing after Expanding Clitics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dNyCwQH_w_m",
        "outputId": "6e838b3d-de07-45ff-9b8e-958e34d2adbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['She',\n",
              " 'is',\n",
              " 'going',\n",
              " 'for',\n",
              " 'a',\n",
              " 'walk',\n",
              " '.',\n",
              " 'Jack',\n",
              " 'did',\n",
              " 'not',\n",
              " 'go',\n",
              " '.',\n",
              " 'They',\n",
              " 'would',\n",
              " 'definitely',\n",
              " 'go',\n",
              " 'tonight',\n",
              " '.',\n",
              " 'I',\n",
              " 'am',\n",
              " 'sorry',\n",
              " ',',\n",
              " 'I',\n",
              " 'will',\n",
              " 'be',\n",
              " 'late',\n",
              " '.',\n",
              " 'That',\n",
              " 'is',\n",
              " 'the',\n",
              " 'way',\n",
              " 'I',\n",
              " 'like',\n",
              " 'them',\n",
              " '!',\n",
              " '!',\n",
              " '!']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokenize(expanded_clitics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1Y0xmAbCGJX"
      },
      "source": [
        "# Tokenization with RegEx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_YgB566COJ7"
      },
      "source": [
        "Compare Regex re.split() to Python's split() without the re library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_R32n5p_-Cw"
      },
      "outputs": [],
      "source": [
        "sentence = \"He's fast. The boy ran up the hill, he can't come back down!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc5G3zVFCUF3",
        "outputId": "c7d756b2-4750-4ed4-da02-8285eb8cbc62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"He's\", 'fast.', 'The', 'boy', 'ran', 'up', 'the', 'hill,he', \"can't\", 'come', 'back', 'down!']\n"
          ]
        }
      ],
      "source": [
        "result = sentence.split()\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beVNbLcGCZOQ",
        "outputId": "b53a28f9-e206-4211-a686-a2e946dcccc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"He's fast\", \"The boy ran up the hill, he can't come back down!\"]\n"
          ]
        }
      ],
      "source": [
        "result = sentence.split(\". \")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2yBigurCv56"
      },
      "source": [
        "Python’s split() method falls short as only one separator can be used at a time. Another thing to note – in word tokenization, split() did not consider punctuation as a separate token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RReXenLDCzI"
      },
      "source": [
        "### Regular Expression (RegEx)\n",
        "library : re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHft_OLPC6XO"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JInVYTRmDjQT"
      },
      "outputs": [],
      "source": [
        "txt = 'uno-dos-tres#quatro cinco 123'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFiO45D3EaDc"
      },
      "source": [
        "split() method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2MihWLuDn23",
        "outputId": "5312036e-ccb8-4024-99c9-a515dcbe92cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['uno', 'dos', 'tres', 'quatro', 'cinco', '123']\n"
          ]
        }
      ],
      "source": [
        "result = print(re.split('\\W+',txt))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sziSEttUEocz",
        "outputId": "2e2f706b-7f22-415b-f9f0-f42cdeab614c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['one', 'two', 'three', '', 'four']\n"
          ]
        }
      ],
      "source": [
        "num = 'one-two-three-#four'\n",
        "result = print(re.split('[-+#]',num))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS0hYQpLEWMy"
      },
      "source": [
        "<font color='#0abde3'> w+ example </font> <br/>\n",
        "**'+'** means any number of times - keep searching <br/> \n",
        "The **“\\w”** represents “any word character” which usually means alphanumeric (letters, numbers) and underscore (_).  <br/> [\\w’]+ signals that the code should find all the alphanumeric characters  <font/>\n",
        "<font color='#0abde3'> <br/> Regular expressions use the backslash character \\ to indicate special forms;\n",
        "\n",
        "<font color= #fd79a8 > Enclose a string with [ ] to match any single character in it. It can be used to split by multiple different characters. <font/> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK3upom-E9C_"
      },
      "source": [
        "# <font color= #fd79a8 > ReGex method to replace strings: re.sub() <font/> \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-tpZ3WjEFhv",
        "outputId": "0a70933c-9b6b-4c3c-d615-f7896d4580a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "one-and-two-and-three-and-four\n"
          ]
        }
      ],
      "source": [
        "string = 'one and two and three and four'\n",
        "result = print(re.sub(' ','-',string))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aY539PCFdLK"
      },
      "source": [
        "# <font color='#1dd1a1'> ReGex method to search strings:  re.search() <font/>\n",
        "The search() function takes the \"pattern\" and \"string\" to scan from the text input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYxd_MLRFNFC"
      },
      "outputs": [],
      "source": [
        "pattern_wanted = ['nlp course','advanced']\n",
        "string = 'The best nlp course for beginners, with awesome practical projects'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os_AnH8JFrs0",
        "outputId": "0e8e2c37-918a-4985-e8cc-92bf4e22b76a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking for \"nlp course\" in \"The best nlp course for beginners, with awesome practical projects\" : \n",
            " \tSearch successful!\n",
            "Looking for \"advanced\" in \"The best nlp course for beginners, with awesome practical projects\" : \n",
            " \t Oh no :( we did not find anything!\n"
          ]
        }
      ],
      "source": [
        "for pattern in pattern_wanted:\n",
        "  print('Looking for \"%s\" in \"%s\" : \\n' %(pattern,string),end=\" \")\n",
        "\n",
        "  if re.search(pattern,string):\n",
        "    print(\"\\tSearch successful!\")\n",
        "  else:\n",
        "    print(\"\\t Oh no :( we did not find anything!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO4YLJH2GkE2"
      },
      "source": [
        "# <font color= #0abde3 > Information Extraction using re.findall  </font> <br/> \n",
        "search() module will only return the first occurrence that matches the specified pattern. <br/>findall() will iterate over all the lines of the file and return all the matches. <br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RfBnMDzGBNu"
      },
      "outputs": [],
      "source": [
        "contact_details = 'Duke Richard 123-1236 duke@dukeemail.com Joe Denver 2020/JAN/05 joeden@gmail.com 2020/DEC/24 john_black23@ymail.com John Black +4265-3588'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAGYqWtiHZ2J"
      },
      "source": [
        "extracting emails from contact details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU55u7uRHZMB",
        "outputId": "b3292ac7-ec8a-4785-d3fa-8ce9d9de0570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "duke@dukeemail.com\n",
            "joeden@gmail.com\n",
            "john_black23@ymail.com\n"
          ]
        }
      ],
      "source": [
        "emailinfo = re.findall(r'[\\w\\.-]+@[\\w\\.-]+',contact_details)\n",
        "\n",
        "for email in emailinfo:\n",
        "  print(email)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTVPSUKZH1xS"
      },
      "source": [
        "we prefix with r as in raw <br/>\n",
        "Regular expressions use the backslash character \\ to indicate special forms; but backslashes are not handled in any special way in a string literal prefixed with 'r'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}